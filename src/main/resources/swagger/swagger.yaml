# Copyright (c) 2000-2020, Board of Trustees of Leland Stanford Jr. University
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice,
# this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright notice,
# this list of conditions and the following disclaimer in the documentation
# and/or other materials provided with the distribution.
#
# 3. Neither the name of the copyright holder nor the names of its contributors
# may be used to endorse or promote products derived from this software without
# specific prior written permission. 
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.

swagger: "2.0"
info:
  title: LOCKSS Crawler Service REST API
  version: 2.0.0
  description: REST API of the LOCKSS Crawler Service
  contact:
    name: LOCKSS Support
    url: 'https://www.lockss.org/'
    email: lockss-support@lockss.org
  license:
    name: BSD-3-Clause
    url: 'https://opensource.org/licenses/BSD-3-Clause'
host: 'laaws.lockss.org:443'
basePath: /
tags:
  - name: crawls
    description: 'requests related to crawls'
  - name: crawlers
    description: 'requests related to crawlers'
schemes:
  - https
produces:
  - application/json
security:
  - basicAuth: []

paths:
  /crawlers:
    get:
      tags:
        - crawlers
      summary: Get the list of supported crawlers.
      description: Return the list of supported crawlers.
      operationId: getCrawlers
      responses:
        '200':
          schema:
            $ref: '#/definitions/crawlerStatuses'
        '404':
          description: No Such Crawler
  '/crawlers/{crawler}':
    get:
      tags:
        - crawlers
      summary: Return information about a crawler.
      description: Get information related to a installed crawler.
      operationId: getCrawlerConfig
      parameters:
        - name: crawler
          in: path
          description: Identifier for the crawler
          required: true
          type: string
      responses:
        '200':
          description: Crawler Configuration Found
          schema:
            $ref: '#/definitions/crawlerConfig'
        '401':
          description: Access Denied.
        '404':
          description: No Such Crawler
        '500':
          description: "Internal Server Error"
  /crawls:
    get:
      tags:
        - crawls
      summary: Get a list of active crawls.
      description: Get a list of all currently active crawls or a pageful of\
        \ the list defined by the continuation token and size
      operationId: getCrawls
      parameters:
        - name: limit
          in: query
          description: The number of jobs per page
          required: false
          type: integer
          default: 50
        - name: continuationToken
          in: query
          description: The continuation token of the next page of jobs to be\
            \ returned.
          required: false
          type: string
      responses:
        '200':
          description: The requested crawls
          schema:
            $ref: '#/definitions/jobPager'
        '400':
          description: "Bad Request"
        '401':
          description: "Unauthorized"
        '500':
          description: "Internal Server Error"
    post:
      tags:
        - crawls
      summary: Request a crawl using a descriptor
      description: Use the information found in the descriptor object to\
        \ initiate a crawl.
      operationId: doCrawl
      parameters:
        - name: 'crawlDesc'
          in: body
          description: crawl request
          required: true
          schema:
            $ref: '#/definitions/crawlDesc'
      responses:
        '202':
          description: The crawl request has been queued for operation.
          schema:
            $ref: '#/definitions/crawl'
        '400':
          description: "Bad Request"
        '401':
          description: "Unauthorized"
        '403':
          description: Forbidden
        '404':
          description: "Not Found"
        '500':
          description: "Internal Server Error"
    delete:
      tags:
        - crawls
      summary: Delete all of the currently queued and active crawl requests
      description: Halt and delete all of the currently queued and active crawls
      operationId: deleteCrawls
      responses:
        '501':
          description: This feature is not implemented.
  /status:
    get:
      tags:
      - "status"
      summary: "Get the status of the service"
      description: "Get the status of the service"
      operationId: "getStatus"
      produces:
      - "application/json"
      responses:
        200:
          description: "The status of the service"
          schema:
            $ref: "#/definitions/apiStatus"
        401:
          description: "Unauthorized"
        500:
          description: "Internal Server Error"
  '/crawls/{jobId}/fetched':
    get:
      tags:
      - crawls
      summary: A pageable list of fetched urls.
      description: Get a list of fetched urls.
      operationId: getCrawlFetched
      parameters:
        - name: jobId
          in: path
          required: true
          type: string
        - name: continuationToken
          in: query
          description: The continuation token of the next page of jobs to be\
            \ returned.
          type: string
        - name: limit
          in: query
          description: The number of jobs per page.
          type: integer
      responses:
        '200':
          description: The requested fetched urls.
          schema:
            $ref: '#/definitions/urlPager'
        '400':
          description: "Bad Request"
        '401':
          description: "Unauthorized"
        '404':
          description: "Not Found"
        '500':
          description: "Internal Server Error"
  '/crawls/{jobId}/excluded':
    get:
      tags:
      - crawls
      summary: A pageable list of excluded urls.
      description: Get a list of excluded urls.
      operationId: getCrawlExcluded
      parameters:
        - name: jobId
          in: path
          description: identifier used to identify a specific crawl.
          required: true
          type: string
        - name: continuationToken
          in: query
          description: The continuation token of the next page of jobs to be\
            \ returned.
          type: string
        - name: limit
          in: query
          description: The number of jobs per page.
          type: integer
      responses:
        '200':
          description: The requested excluded urls.
          schema:
            $ref: '#/definitions/urlPager'
        '400':
          description: "Bad Request"
        '401':
          description: "Unauthorized"
        '404':
          description: "Not Found"
        '500':
          description: "Internal Server Error"
  '/crawls/{jobId}/notModified':
    get:
      tags:
      - crawls
      summary: A pageable list of not modified urls.
      description: Get a list of not modified urls.
      operationId: getCrawlNotModified
      parameters:
        - name: jobId
          in: path
          required: true
          type: string
        - name: continuationToken
          in: query
          description: The continuation token of the next page of jobs to be\
            \ returned.
          type: string
        - name: limit
          in: query
          description: The number of jobs per page.
          type: integer
      responses:
        '200':
          description: The requested not modified urls.
          schema:
            $ref: '#/definitions/urlPager'
        '400':
          description: "Bad Request"
        '401':
          description: "Unauthorized"
        '404':
          description: "Not Found"
        '500':
          description: "Internal Server Error"
  '/crawls/{jobId}/pending':
    get:
      tags:
      - crawls
      summary: A pageable list of pending urls.
      description: Get a list of pending urls.
      operationId: getCrawlPending
      parameters:
        - name: jobId
          in: path
          required: true
          type: string
        - name: continuationToken
          in: query
          description: The continuation token of the next page of jobs to be\
            \ returned.
          type: string
        - name: limit
          in: query
          description: The number of jobs per page.
          type: integer
      responses:
        '200':
          description: The requested pending urls.
          schema:
            $ref: '#/definitions/urlPager'
        '400':
          description: "Bad Request"
        '401':
          description: "Unauthorized"
        '404':
          description: "Not Found"
        '500':
          description: "Internal Server Error"
  '/crawls/{jobId}/parsed':
    get:
      tags:
      - crawls
      summary: A pageable list of parsed urls.
      description: Get a list of parsed urls.
      operationId: getCrawlParsed
      parameters:
        - name: jobId
          in: path
          required: true
          type: string
        - name: continuationToken
          in: query
          description: The continuation token of the next page of jobs to be\
            \ returned.
          type: string
        - name: limit
          in: query
          description: The number of jobs per page.
          type: integer
      responses:
        '200':
          description: The requested parsed urls.
          schema:
            $ref: '#/definitions/urlPager'
        '400':
          description: "Bad Request"
        '401':
          description: "Unauthorized"
        '404':
          description: "Not Found"
        '500':
          description: "Internal Server Error"
  '/crawls/{jobId}/errors':
    get:
      tags:
      - crawls
      summary: A pageable list of urls with errors.
      description: Get a list of urls with errors.
      operationId: getCrawlErrors
      parameters:
        - name: jobId
          in: path
          required: true
          type: string
        - name: continuationToken
          in: query
          description: The continuation token of the next page of jobs to be\
            \ returned.
          type: string
        - name: limit
          in: query
          description: The number of jobs per page.
          type: integer
      responses:
        '200':
          description: The requested urls with errors.
          schema:
            $ref: '#/definitions/urlPager'
        '400':
          description: "Bad Request"
        '401':
          description: "Unauthorized"
        '404':
          description: "Not Found"
        '500':
          description: "Internal Server Error"
  '/crawls/{jobId}/mimeType/{type}':
    get:
      tags:
        - crawls
      summary: A pageable list of urls of mimetype.
      description: Get a list of urls of mimetype.
      operationId: getCrawlByMimeType
      parameters:
        - name: jobId
          in: path
          required: true
          type: string
        - name: type
          in: path
          required: true
          type: string
        - name: continuationToken
          in: query
          description: The continuation token of the next page of jobs to be\
            \ returned.
          type: string
        - name: limit
          in: query
          description: The number of jobs per page.
          type: integer
      responses:
        '200':
          description: The requested urls.
          schema:
            $ref: '#/definitions/urlPager'
        '400':
          description: "Bad Request"
        '401':
          description: "Unauthorized"
        '404':
          description: "Not Found"
        '500':
          description: "Internal Server Error"
  '/crawls/{jobId}':
    get:
      tags:
        - crawls
      summary: Get the crawl info for this job
      description: Get the job represented by this crawl id
      operationId: getCrawlById
      parameters:
        - name: jobId
          in: path
          required: true
          type: string
      responses:
        '200':
          description: The crawl status of the requested crawl
          schema:
            $ref: '#/definitions/crawlStatus'
        '401':
          description: "Unauthorized"
        '404':
          description: "Not Found"
        '500':
          description: "Internal Server Error"
    delete:
      summary: Remove or stop a crawl
      tags:
      - crawls
      description: >-
        Delete a crawl given the crawl identifier, stopping any current
        processing, if necessary.
      operationId: deleteCrawlById
      parameters:
        - name: jobId
          in: path
          description: identifier used to identify a specific crawl.
          required: true
          type: string
      responses:
        '200':
          description: The deleted crawl
          schema:
            $ref: '#/definitions/crawlStatus'
        '401':
          description: "Unauthorized"
        '403':
          description: Forbidden
        '404':
          description: "Not Found"
        '500':
          description: "Internal Server Error"
securityDefinitions:
  basicAuth:
    description: "HTTP Basic Authentication. Works over `HTTP` and `HTTPS`"
    type: "basic"
definitions:
  crawlerStatuses:
    type: "object"
    properties:
      crawlerMap:
        type: object
        description: An map of crawler status objects
        additionalProperties:
          $ref: '#/definitions/crawlerStatus'
    description: "The metadata generated for a single item"
  mimeCounter:
    description: A counter for mimeTypes seen during a crawl.
    required:
      - mimeType
      - counts
    type: object
    properties:
      mimeType:
        description: The mime type to count.
        type: string
      count:
        format: int32
        description: The number of elements of mime type
        type: integer
      counterLink:
        description: A link to the list of count elements or to a pager with\
          \ count elements.
        type: string
  pageInfo:
    description: The information related to pagination of content
    required:
      - curLink
      - continuationToken
      - resultsPerPage
      - totalCount
    type: object
    properties:
      totalCount:
        format: int32
        description: The total number of elements to be paginated
        type: integer
      resultsPerPage:
        format: int32
        description: The number of results per page.
        type: integer
      continuationToken:
        description: The continuation token.
        type: string
      curLink:
        description: The link to the current page.
        type: string
      nextLink:
        description: The link to the next page.
        type: string
  status:
    description: A status which includes a code and a message.
    required:
    - code
    - msg
    type: object
    properties:
      code:
        format: int32
        description: The numeric value for this status.
        type: integer
      msg:
        description: A text message explaining this status.
        type: string
  apiStatus:
    type: "object"
    required:
    - "version"
    - "ready"
    properties:
      version:
        type: "string"
        description: "The version of the service"
      ready:
        type: "boolean"
        description: "The indication of whether the service is available"
    description: "The status information of the service"
  counter:
    description: A counter for urls.
    required:
      - count
      - itemsLink
    properties:
      count:
        format: int32
        description: The number of elements
        type: integer
      itemsLink:
        description: A link to the list of count items or to a pager with count\
          \ items.
        type: string
  crawlDesc:
    description: A descriptor for a crawl.
    required:
      - auId
      - crawlKind
    type: object
    properties:
      auId:
        description: The identifier of the archival unit to be crawled.
        type: string
      crawlKind:
        description: The kind of crawl being performed. For now, this is either\
          \ FollowLinkCrawler or RepairCrawler.
        type: string
      crawler:
        description: The crawler to be used for this crawl.
        type: string
        default: lockss
      repairList:
        description: The repair URLs in a repair crawl.
        type: array
        items:
          type: string
      forceCrawl:
        description: An indication of whether the crawl is to be forced, even\
          \ if outside the crawl window.
        type: boolean
        default: false
      refetchDepth:
        description: The refetch depth to use for a deep crawl.
        type: integer
        format: int32
        default: -1
      priority:
        description: The priority for the crawl.
        type: integer
        format: int32
      crawlList:
        type: "array"
        description: The list of URLs to crawl.
        items:
          type: "string"
      crawlDepth:
        type: "integer"
        description: The depth of the crawl.
      tags:
        type: "array"
        description: The tags to include, if different from default anchor tags.
        items:
          type: "string"
      includeRegex:
        type: "array"
        description: A list of regular expressions of URLS to include, if not\
          \ in the exclude list.
        items:
          type: "string"
      excludeRegex:
        type: "array"
        description: A list of regular expressions of URLS to exclude.
        items:
          type: "string"
  crawl:
    description: The result from a request to perform a crawl.
    required:
    - crawlDesc
    - "creationDate"
    - "jobId"
    - "status"
    type: object
    properties:
      crawlDesc:
        description: The descriptor of the crawl.
        $ref: '#/definitions/crawlDesc'
      creationDate:
        type: "string"
        format: "date"
        description: The time, in ISO-8601 format, the crawl was requested.
        example: "yyyy-MM-ddTHH:mm:ss.SSSZ"
      jobId:
        description: Identifier of the job performing the crawl.
        type: "string"
      status:
        description: The status of the crawl operation.
        $ref: "#/definitions/status"
      startDate:
        type: "string"
        format: "date"
        description: The time, in ISO-8601 format, the crawl began.
        example: "yyyy-MM-ddTHH:mm:ss.SSSZ"
      endDate:
        type: "string"
        format: "date"
        description: The time, in ISO-8601 format, the crawl ended.
        example: "yyyy-MM-ddTHH:mm:ss.SSSZ"
      result:
        type: "string"
        description: A URI which can be used to retrieve the crawl data.
      delayReason:
        description: The reason for any delay in performing the operation.
        type: string
  crawlerStatus:
    description: Status about a specific crawler.
    required:
    - isEnabled
    - isRunning
    type: object
    properties:
      isEnabled:
        description: Is the crawler enabled
        type: boolean
      isRunning:
        description: Is the crawl starter running
        type: boolean
      errStatus:
        $ref: '#/definitions/status'
  crawlerConfig:
    description: Configuration information about a specific crawler.
    required:
      - configMap
    type: object
    properties:
      configMap:
        description: key value pairs specific providing configuration\
          \ information.
        type: object
        additionalProperties:
          type: string
  crawlStatus:
    description: The status of a single crawl.
    required:
      - key
      - auId
      - auName
      - startUrls
      - type
      - startTime
      - endTime
      - status
      - priority
    type: object
    properties:
      key:
        description: The id for the crawl.
        type: string
      auId:
        description: The id for the au.
        type: string
      auName:
        description: The name for the au.
        type: string
      type:
        description: The type of crawl.
        type: string
      startUrls:
        description: The array of start urls.
        type: array
        items:
          type: string
      priority:
        format: int32
        description: The priority for this crawl.
        type: integer
      sources:
        description: The sources to use for the crawl.
        type: array
        items:
          type: string
      depth:
        format: int32
        description: The depth of the crawl.
        type: integer
      refetchDepth:
        format: int32
        description: The refetch depth of the crawl.
        type: integer
      proxy:
        description: The proxy used for crawling.
        type: string
      startTime:
        format: int64
        description: The timestamp for the start of crawl.
        type: integer
      endTime:
        format: int64
        description: The timestamp for the end of the crawl.
        type: integer
      status:
        $ref: '#/definitions/status'
      isWaiting:
        description: True if the crawl wating to start.
        type: boolean
      isActive:
        description: True if the crawl is active.
        type: boolean
      isError:
        description: True if the crawl has errored.
        type: boolean
      bytesFetched:
        format: int64
        description: The number of bytes fetched.
        type: integer
      fetchedItems:
        $ref: '#/definitions/counter'
      excludedItems:
        $ref: '#/definitions/counter'
      notModifiedItems:
        $ref: '#/definitions/counter'
      parsedItems:
        $ref: '#/definitions/counter'
      pendingItems:
        $ref: '#/definitions/counter'
      errors:
        $ref: '#/definitions/counter'
      mimeTypes:
        description: The list of urls by mimeType.
        type: array
        items:
          $ref: '#/definitions/mimeCounter'
  urlPager:
    description: A Pager for urls with maps.
    required:
      - pageInfo
      - urls
    type: object
    properties:
      pageInfo:
        $ref: '#/definitions/pageInfo'
      urls:
        description: An list of url with related info.
        type: array
        items:
          $ref: '#/definitions/urlInfo'
  jobPager:
    description: A display page of jobs
    required:
      - jobs
      - pageInfo
    type: object
    properties:
      jobs:
        description: The jobs displayed in the page
        type: array
        items:
          $ref: '#/definitions/crawlStatus'
      pageInfo:
        $ref: '#/definitions/pageInfo'
  urlInfo:
    description: information related to an url.
    required:
      - url
    type: object
    properties:
      url:
        description: The url string
        type: string
      error:
        $ref: '#/definitions/urlError'
      referrers:
        description: An optional list of referrers.
        type: array
        items:
          type: string
  urlError:
    description: information related to an error for a url.
    required:
    - message
    - severity
    properties:
      message:
        description: The error message
        type: string
      severity:
        description: the severity of the error.
        type: string
        enum:
          - Warning
          - Error
          - Fatal
